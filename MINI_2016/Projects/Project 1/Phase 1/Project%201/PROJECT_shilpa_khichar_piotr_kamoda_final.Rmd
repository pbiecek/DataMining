---
title: "PROJECT_1_PART_1_PK_SK"
author: "Piotr Kamoda & Shilpa Khichar"
date: "31 October 2016"
output: html_document
---
```{r code=FALSE }
#The goal is :1)to develop two multi-class classifiers, 
#               that predicts the (nearly)correct labels(popularity levels ) for the test data set and               
#             2)to find better performing classifier(decision tree and random forest used here) 
```

```{r setup, include=FALSE}

library("C50")
library("party")
library("randomForest")
library("ROCR")
library("e1071")
library("caret")
library("magrittr")
library("plyr")
library("class")

```

```{r code_knn}
#The goal here is to predict the level of popularity of an article from the dataset "OnlineNewsPopularity"
#There are 2 classes we are trying to predict are:(1) not so popular , and 
#                                                 (2) viral or very popular, articles that are shared.


#Reading data from CSV file to R dataset:
data <- read.csv(file.path(file.path(getwd(), "OnlineNewsPopularity"), "OnlineNewsPopularity.csv"), header=TRUE, sep=",", encoding="UTF-8")


## dividing our dataset into 2 classes based on the no of shares:

#data$class <- with( data
#                    , ifelse(shares < 800 ,1 
#                             ,ifelse(shares >= 800 & shares < 1000 ,2 
#                                     ,ifelse(shares >= 1000 & shares < 2000 ,3 
#                                             ,ifelse(shares >= 2000 & shares < 2000000 ,4 ,5)))))
data$class <- with( data, ifelse(shares < 1500 ,1 ,2))
##Checking the frequency of each class
table(data$class)

## Removing url, timedelta, and shares attributes
## They are non-predictive variables,as they are not appropriate for classification features:
useless <- names(data) %in% c("url","timedelta","shares")
Online_useful <-data[!useless]

## near zero variance variables are those that have one unique value or 
##                              they have very few unique values relative to the number of samples or
##                              the ratio of frequency of most common value to the frequency of second most common value is large. 
## so Removing the near zero variance variables, will make our dataset less unstable
nzv <- nearZeroVar(Online_useful, saveMetrics= TRUE)
nzv
##so we see that kw_min_max: Best keyword (min. shares) has value TRUE for near zero variance
# Column name                    freqRatio    percentUnique   zeroVar   nzv
# kw_min_max                     45.139842    2.57542125      FALSE     TRUE

## next step is to remove this variable from our dataset:
nzv <- nearZeroVar(Online_useful)
nzv
online_nzv <- Online_useful[, -nzv]
str(online_nzv)
## so we have filtered our dataset, which doesnot have problematic variable:Best keyword (min. shares)

## checking corellation,corellation refers to the extent to which two variables have a linear relationship with each other. ## Correlation is checked only for numeric variables, in all case all variables.
high.corr.num <- findCorrelation(cor(online_nzv), cutoff = .75)
names(online_nzv)[high.corr.num]
##so we get these variable as hightly correlated variables:"kw_avg_avg" 
##                                                         "data_channel_is_world"
##                                                         "rate_negative_words" 
##                                                         "LDA_00"                
##                                                         "kw_min_min"                
##                                                         "self_reference_max_shares"
##                                                         "kw_max_min"                
##                                                         "self_reference_min_shares"
##                                                         "n_non_stop_words"         
##                                                         "n_unique_tokens"
kw_avg_avg = online_nzv$kw_avg_avg    
kw_min_min = online_nzv$kw_min_min     
cor(kw_min_min, kw_avg_avg)      


myvars <- names(online_nzv) %in% c("kw_avg_avg" ,
                                                         "data_channel_is_world",
                                                         "rate_negative_words" ,
                                                         "LDA_00"               , 
                                                         "kw_min_min"            ,    
                                                         "self_reference_max_shares",
                                                         "kw_max_min"                ,
                                                         "self_reference_min_shares",
                                                         "n_non_stop_words"         ,
                                                         "n_unique_tokens")
online_corr <-online_nzv[myvars]
cor(online_corr)                                                           
## for visualization of correlated variables and there dependencies:     
library(ggplot2)
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(cor(online_corr, use="p")), fill=value, geom="tile") + scale_fill_gradient2(limits=c(-1, 1))

## Removing correlated variables:"n_non_stop_words","kw_max_min","kw_min_min" ,"LDA_00", "kw_avg_avg" , ,"self_reference_max_shares".
## And keeping these variables in the data set:"data_channel_is_world", "rate_negative_words", "self_reference_min_shares", "n_unique_tokens".
useless2 <- names(online_nzv ) %in% c("n_non_stop_words",
                                          "kw_max_min",
                                          "kw_min_min" ,
                                          "LDA_00", 
                                          "kw_avg_avg"  ,
                                          "self_reference_max_shares")
Online <- online_nzv[!useless2]
str(Online)
# we are able to cut short 10 variable , but still our data is huge so we will perform our test on less number of records, for better performance

## now we convert class variable from numeric to factor variable, as class is our target variable
Online$class = factor(Online$class)

##Checking structure of our table, to be sure of above conversion:
str(Online)

#Applying selection filter
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", verbose = FALSE, repeats = 5)
rfWithFilter <- sbf(form = class ~ ., data = Online[0:1000,], sbfControl = filterCtrl, allowParallel = TRUE)
rfWithFilter
#help
#During resampling, the top 5 selected variables (out of a possible 32):
#   data_channel_is_bus (100%), data_channel_is_socmed (100%), data_channel_is_tech (100%), is_weekend (100%), kw_max_max (100%)

## class variable is  normalized here
preProcValues <- preProcess(Online, method = c("range"))

set.seed(20)

indxTrain <- createDataPartition(y = Online$class, p = 0.05)
Online_train <- predict(preProcValues, Online[indxTrain$Resample1, ])
indxTrain <- createDataPartition(y = Online$class, p = 0.05)
Online_test <- predict(preProcValues,Online[indxTrain$Resample1, ])

#Online_train <- Online[indxTrain$Resample1,]
#Online_test <- Online[-indxTrain$Resample1,]

len <- min(dim(Online_train)[1], dim(Online_test)[1])

Online_train <- Online_train[0:len,]
Online_test <- Online_test[0:len,]


## we predict class(from class variable) for selected variables in our dataset 
## we can check performance for k = 0 to sqrt(no of observation), to find best k.
tuneK <- 1:50
## performing KNN with all possible k values and finding out which K values gives best performance
performance_v <- sapply(tuneK, function(k) {
## Performing KNN on the training data set  
   knnFit <- knn3(class ~ data_channel_is_bus + 
                    data_channel_is_socmed + 
                    data_channel_is_tech + 
                    is_weekend + 
                    kw_max_max
                  , data = Online_train, k=k, prob = FALSE, use.all = FALSE)
## Predicting classes for test data set    
## creating cross table to see discrepancy between actual and predicted classes  
  tab <- table(true = Online_test$class , predict = predict(knnFit, Online_test, type="class"))
  sum(diag(tab)) / sum(tab)
}) #help
optimal_k = which.max(performance_v)
optimal_k
performance_v[optimal_k]
## ploting graph between performance and K(all possible k values)
df <- data.frame(tuneK, performance_v)
ggplot(df, aes(tuneK, performance_v)) +
  geom_point() + 
  geom_smooth(se=FALSE, span=0.1, size=2) +
  theme_bw()

#Classifying with the optimal k:
knnFit <- knn3(class ~ data_channel_is_bus + 
                    data_channel_is_socmed + 
                    data_channel_is_tech + 
                    is_weekend + 
                    kw_max_max, data = Online_train, k=optimal_k)
knnFit
pred_optimal <- predict(knnFit, Online_test, type="class")
tab_optimal <- table(true = Online_test$class, predicted = pred_optimal)
sum(diag(tab_optimal)) / sum(tab_optimal)

#Accuracy : the percentage of the correct prediction . (TP + TN) / (TP + TN + FP + FN) 
sum(diag(tab_optimal)) / sum(tab_optimal)

#Precision : The percentage of positive predictions that are correct (Positive = 0, negative = 1). TP / (TP + FP)
tab_optimal[[1]] / (tab_optimal[[1]] + tab_optimal[[2]])

#Sensitivity : The percentage of positive labeled instances that were predicted as positive. TP / (TP + FN)
tab_optimal[[1]] / (tab_optimal[[1]] + tab_optimal[[3]])

#Specificity : The percentage of negative labeled instances that were predicted as negative. TN / (TN + FP)
tab_optimal[[4]] / (tab_optimal[[4]] + tab_optimal[[2]])


### classifying data with decision tree and  measuring performance:
d_Tree <- ctree(class ~ data_channel_is_bus + 
                    data_channel_is_socmed + 
                    data_channel_is_tech + 
                    is_weekend + 
                    kw_max_max
                  , data = Online_train )
d_Tree

plot(d_Tree)
predictions <- predict(d_Tree, Online_test)
table(predictions, Online_test$class)


tab<-table(real = Online_test$class,
      predicted = predictions)
tab

confusionMatrix(predictions, Online_test$class) 

## creating cross table to generate the performance measurements of the prediction result: 
#library(gmodels)
#ctab <- CrossTable(Online_train$class,predicted=online_test)
#ctab
#help

#Accuracy : the percentage of the correct prediction . (TP + TN) / (TP + TN + FP + FN) 
#Accuracy <- sum(diag(tab)) / sum(tab)
#Precision : The percentage of positive predictions that are correct (Positive = 0, negative = 1). TP / (TP + FP)
#Precision <- diag(tab) / rowSums(tab)
#Recall : []
#Recall <- (diag(tab) / colSums(tab))

#a<-ctab$prop.tbl
#p_o <- ctab$prop.tbl[1,1] + ctab$prop.tbl[2,2]
#p_o  

#p_e <- (ctab$prop.tbl[1,1]+ctab$prop.tbl[2,1]) * (ctab$prop.tbl[1,1]+ctab$prop.tbl[1,2]) +
#       (ctab$prop.tbl[2,1]+ctab$prop.tbl[2,2]) * (ctab$prop.tbl[1,2]+ctab$prop.tbl[2,2])
#p_e 

#kappa = (p_o - p_e) / (1 - p_e) ##Cohen's Kappa = (Observed agreement - Agreement by chance)/(1 - Agreement by chance)
#kappa  
```

```{r code}
library(randomForest)
r_fit <- randomForest(class ~ data_channel_is_bus + 
                    data_channel_is_socmed + 
                    data_channel_is_tech + 
                    is_weekend + 
                    kw_max_max, data = Online_train , importance = TRUE)
prob <- predict(r_fit, type="prob")[,2]


library(ROCR)
fit.pred = prediction(prob, Online_test$class)
fit.perf = performance(fit.pred,"tpr","fpr")
plot(fit.perf)
abline(a=0,b=1)

fit.pred = prediction(prob, Online_test$class)
fit.perf = performance(fit.pred,"tpr","fpr")
plot(fit.perf, colorize=TRUE)
abline(a=0,b=1)

##Multiple curves
library(caret)

r_fit <- randomForest(class ~ data_channel_is_bus + 
                    data_channel_is_socmed + 
                    data_channel_is_tech + 
                    is_weekend + 
                    kw_max_max, data = Online_train , importance = TRUE, mtry=3)
prob <- predict(r_fit, type="prob")[,2]

knn_fit <- knn3(class ~ data_channel_is_bus + 
                    data_channel_is_socmed + 
                    data_channel_is_tech + 
                    is_weekend + 
                    kw_max_max, data = Online_train, k=optimal_k)
prob2 <- predict(knn_fit, newdata = Online_test, type="prob")[,2]

fit.pred = prediction(prob, Online_test$class)
fit.perf = performance(fit.pred,"tpr","fpr")
plot(fit.perf, col="red3")
fit.pred2 = prediction(prob2, Online_test$class)
fit.perf2 = performance(fit.pred2,"tpr","fpr")
plot(fit.perf2, col="blue3", add=TRUE)
abline(a=0,b=1)


##AUC (Area Under the Curve)
fit.pred = prediction(prob, Online_test$class)
fit.perf = performance(fit.pred,"auc")
fit.perf@y.values[[1]]
```

## Conclusion
Knn fit is better, as concluded from plots (more area under the ROC curve).
